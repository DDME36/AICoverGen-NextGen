{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# üéµ AICoverGen NextGen\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DDME36/AICoverGen-NextGen/blob/main/AICoverGen_NextGen_Colab.ipynb)\n",
        "\n",
        "**Create AI Cover songs with any voice**\n",
        "\n",
        "---\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| üé§ BS-RoFormer | SOTA Vocal Separation (SDR 12.97) |\n",
        "| üîá DeEcho-DeReverb | Remove Echo & Reverb |\n",
        "| üéµ RVC v2 | High Quality Voice Conversion |\n",
        "| üéõÔ∏è FCPE/Hybrid | Smoother Pitch Detection |\n",
        "| ‚ö° Optimized | Fast inference with torch.compile |\n",
        "\n",
        "---\n",
        "\n",
        "**How to use:** Run Cell 1 ‚Üí Run Cell 2 to start WebUI\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "install"
      },
      "outputs": [],
      "source": [
        "#@title 1Ô∏è‚É£ **Install** (Run once, ~3-4 minutes)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üéµ AICoverGen NextGen - Optimized Installation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Python 3.10 (if needed)\n",
        "print(\"\\n[1/4] üêç Checking Python...\")\n",
        "if sys.version_info.minor == 12:\n",
        "    !sudo apt-get update -qq && sudo apt-get install -y -qq python3.10 python3.10-distutils python3.10-dev\n",
        "    !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1\n",
        "    !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2\n",
        "    !curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
        "print(\"‚úì Python ready\")\n",
        "\n",
        "# Step 2: Clone\n",
        "print(\"\\n[2/4] üìÇ Cloning repository...\")\n",
        "REPO = '/content/AICoverGen-NextGen'\n",
        "if os.path.exists(REPO):\n",
        "    !cd {REPO} && git pull -q\n",
        "else:\n",
        "    !git clone -q --depth 1 https://github.com/DDME36/AICoverGen-NextGen.git {REPO}\n",
        "os.chdir(REPO)\n",
        "print(\"‚úì Repository ready\")\n",
        "\n",
        "# Step 3: Dependencies (optimized - parallel install)\n",
        "print(\"\\n[3/4] üì¶ Installing dependencies...\")\n",
        "!sudo apt-get install -y -qq build-essential python3-dev sox libsox-fmt-all 2>/dev/null\n",
        "\n",
        "# Uninstall old torch first\n",
        "!pip uninstall -y torch torchaudio torchvision -q 2>/dev/null\n",
        "\n",
        "# Install all packages in parallel batches for speed\n",
        "!pip install -q --no-cache-dir \\\n",
        "    torch==2.5.1 torchaudio==2.5.1 torchvision==0.20.1 \\\n",
        "    --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "!pip install -q --no-cache-dir \\\n",
        "    gradio==3.50.2 numpy==1.26.4 scipy==1.13.1 \\\n",
        "    librosa==0.10.2 soundfile pydub pedalboard pyworld praat-parselmouth \\\n",
        "    onnxruntime-gpu faiss-cpu torchcrepe torchfcpe \\\n",
        "    fairseq==0.12.2 \"audio-separator[gpu]\" \\\n",
        "    yt-dlp sox ffmpeg-python\n",
        "\n",
        "print(\"‚úì Dependencies installed\")\n",
        "\n",
        "# Step 4: Models\n",
        "print(\"\\n[4/4] ü§ñ Downloading AI models...\")\n",
        "!python setup_models.py\n",
        "\n",
        "# Enable torch optimizations\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "clear_output()\n",
        "print(\"=\"*60)\n",
        "print(\"‚úÖ Installation Complete!\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "print(\"üì¶ Installed:\")\n",
        "print(\"   ‚Ä¢ PyTorch 2.5.1 + CUDA 12.1 (optimized)\")\n",
        "print(\"   ‚Ä¢ BS-RoFormer (Vocal Separation)\")\n",
        "print(\"   ‚Ä¢ FCPE/Hybrid Pitch Detection\")\n",
        "print(\"   ‚Ä¢ RVC v2 + Auto-Mix\")\n",
        "print()\n",
        "print(\"‚ö° Optimizations enabled:\")\n",
        "print(\"   ‚Ä¢ cuDNN benchmark mode\")\n",
        "print(\"   ‚Ä¢ TF32 acceleration\")\n",
        "print()\n",
        "print(\"üëâ Now run Cell 2 to start WebUI!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "run"
      },
      "outputs": [],
      "source": [
        "#@title 2Ô∏è‚É£ **Run WebUI** üöÄ\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "os.chdir('/content/AICoverGen-NextGen')\n",
        "\n",
        "# Clear GPU memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Enable optimizations\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# Fix np.int deprecation\n",
        "with open('src/vc_infer_pipeline.py', 'r') as f:\n",
        "    content = f.read().replace('astype(np.int)', 'astype(int)')\n",
        "with open('src/vc_infer_pipeline.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "# Fix matplotlib backend\n",
        "for key in ['MPLBACKEND', 'DISPLAY']:\n",
        "    if key in os.environ:\n",
        "        del os.environ[key]\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "\n",
        "# Show GPU info\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"üñ•Ô∏è  GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"üéµ AICoverGen NextGen\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "print(\"‚è≥ Starting WebUI...\")\n",
        "print(\"üîó Click the https://xxxxx.gradio.live link below\")\n",
        "print()\n",
        "print(\"üìù Quick Guide:\")\n",
        "print(\"   1. Download voice model in 'Download model' tab\")\n",
        "print(\"   2. Go to 'Generate' tab\")\n",
        "print(\"   3. Paste YouTube link or upload file\")\n",
        "print(\"   4. Select voice model & click Generate\")\n",
        "print()\n",
        "print(\"üéöÔ∏è Pitch Detection:\")\n",
        "print(\"   ‚Ä¢ rmvpe: Fast, clear vocals\")\n",
        "print(\"   ‚Ä¢ fcpe: Smoother, less robotic\")\n",
        "print(\"   ‚Ä¢ hybrid: Best quality (recommended)\")\n",
        "print()\n",
        "print(\"‚ö†Ô∏è  Keep this cell running!\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "!python src/webui.py --share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
