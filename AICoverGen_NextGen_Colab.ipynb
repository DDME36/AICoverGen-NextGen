{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "<div align=\"center\">\n",
        "\n",
        "# ğŸµ AICoverGen NextGen\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DDME36/AICoverGen-NextGen/blob/main/AICoverGen_NextGen_Colab.ipynb)\n",
        "\n",
        "**Create AI Cover songs with any voice**\n",
        "\n",
        "---\n",
        "\n",
        "| Feature | Description |\n",
        "|---------|-------------|\n",
        "| ğŸ¤ BS-RoFormer | SOTA Vocal Separation (SDR 12.97) |\n",
        "| ğŸ”‡ DeEcho-DeReverb | Remove Echo & Reverb |\n",
        "| ğŸµ RVC v2 | High Quality Voice Conversion |\n",
        "| ğŸ›ï¸ FCPE/Hybrid | Smoother Pitch Detection |\n",
        "| âš¡ Optimized | Fast inference with torch.compile |\n",
        "\n",
        "---\n",
        "\n",
        "**How to use:** Run Cell 1 â†’ Run Cell 2 to start WebUI\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "install"
      },
      "outputs": [],
      "source": [
        "#@title 1ï¸âƒ£ **Install** (Run once, ~3-4 minutes)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸµ AICoverGen NextGen - Optimized Installation\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Step 1: Python 3.10 (if needed)\n",
        "print(\"\\n[1/4] ğŸ Checking Python...\")\n",
        "if sys.version_info.minor == 12:\n",
        "    !sudo apt-get update -qq && sudo apt-get install -y -qq python3.10 python3.10-distutils python3.10-dev\n",
        "    !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1\n",
        "    !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 2\n",
        "    !curl -sS https://bootstrap.pypa.io/get-pip.py | python3.10\n",
        "print(\"âœ“ Python ready\")\n",
        "\n",
        "# Step 2: Clone\n",
        "print(\"\\n[2/4] ğŸ“‚ Cloning repository...\")\n",
        "REPO = '/content/AICoverGen-NextGen'\n",
        "if os.path.exists(REPO):\n",
        "    !cd {REPO} && git pull -q\n",
        "else:\n",
        "    !git clone -q --depth 1 https://github.com/DDME36/AICoverGen-NextGen.git {REPO}\n",
        "os.chdir(REPO)\n",
        "print(\"âœ“ Repository ready\")\n",
        "\n",
        "# Step 3: Dependencies (optimized - parallel install)\n",
        "print(\"\\n[3/4] ğŸ“¦ Installing dependencies...\")\n",
        "!sudo apt-get install -y -qq build-essential python3-dev sox libsox-fmt-all 2>/dev/null\n",
        "\n",
        "# Uninstall old torch first\n",
        "!pip uninstall -y torch torchaudio torchvision -q 2>/dev/null\n",
        "\n",
        "# Fix pip version for fairseq compatibility\n",
        "!pip install -q \"pip<24.1\"\n",
        "\n",
        "# Install PyTorch with CUDA\n",
        "!pip install -q torch==2.5.1 torchaudio==2.5.1 torchvision==0.20.1 --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q gradio==3.50.2 numpy==1.26.4 scipy==1.13.1\n",
        "!pip install -q librosa==0.10.2 soundfile pydub pedalboard pyworld praat-parselmouth\n",
        "!pip install -q onnxruntime-gpu faiss-cpu torchcrepe torchfcpe\n",
        "!pip install -q fairseq==0.12.2\n",
        "!pip install -q \"audio-separator[gpu]\"\n",
        "!pip install -q yt-dlp sox ffmpeg-python\n",
        "!pip install -q \"numpy<2\"\n",
        "\n",
        "print(\"âœ“ Dependencies installed\")\n",
        "\n",
        "# Step 4: Models\n",
        "print(\"\\n[4/4] ğŸ¤– Downloading AI models...\")\n",
        "!python setup_models.py\n",
        "\n",
        "# Enable torch optimizations\n",
        "import torch\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "clear_output()\n",
        "print(\"=\"*60)\n",
        "print(\"âœ… Installation Complete!\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "print(\"ğŸ“¦ Installed:\")\n",
        "print(\"   â€¢ PyTorch 2.5.1 + CUDA 12.1 (optimized)\")\n",
        "print(\"   â€¢ BS-RoFormer (Vocal Separation)\")\n",
        "print(\"   â€¢ FCPE/Hybrid Pitch Detection\")\n",
        "print(\"   â€¢ RVC v2 + Auto-Mix\")\n",
        "print()\n",
        "print(\"âš¡ Optimizations enabled:\")\n",
        "print(\"   â€¢ cuDNN benchmark mode\")\n",
        "print(\"   â€¢ TF32 acceleration\")\n",
        "print()\n",
        "print(\"ğŸ‘‰ Now run Cell 2 to start WebUI!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "run"
      },
      "outputs": [],
      "source": [
        "#@title 2ï¸âƒ£ **Run WebUI** ğŸš€\n",
        "\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "\n",
        "os.chdir('/content/AICoverGen-NextGen')\n",
        "\n",
        "# Clear GPU memory\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Enable optimizations\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.backends.cuda.matmul.allow_tf32 = True\n",
        "torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "# Fix np.int deprecation\n",
        "with open('src/vc_infer_pipeline.py', 'r') as f:\n",
        "    content = f.read().replace('astype(np.int)', 'astype(int)')\n",
        "with open('src/vc_infer_pipeline.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "# Fix matplotlib backend\n",
        "for key in ['MPLBACKEND', 'DISPLAY']:\n",
        "    if key in os.environ:\n",
        "        del os.environ[key]\n",
        "os.environ['MPLBACKEND'] = 'Agg'\n",
        "\n",
        "# Show GPU info\n",
        "if torch.cuda.is_available():\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"ğŸ–¥ï¸  GPU: {gpu_name} ({gpu_mem:.1f} GB)\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"ğŸµ AICoverGen NextGen\")\n",
        "print(\"=\"*60)\n",
        "print()\n",
        "print(\"â³ Starting WebUI...\")\n",
        "print(\"ğŸ”— Click the https://xxxxx.gradio.live link below\")\n",
        "print()\n",
        "print(\"ğŸ“ Quick Guide:\")\n",
        "print(\"   1. Download voice model in 'Download model' tab\")\n",
        "print(\"   2. Go to 'Generate' tab\")\n",
        "print(\"   3. Paste YouTube link or upload file\")\n",
        "print(\"   4. Select voice model & click Generate\")\n",
        "print()\n",
        "print(\"ğŸšï¸ Pitch Detection:\")\n",
        "print(\"   â€¢ rmvpe: Fast, clear vocals\")\n",
        "print(\"   â€¢ fcpe: Smoother, less robotic\")\n",
        "print(\"   â€¢ hybrid: Best quality (recommended)\")\n",
        "print()\n",
        "print(\"âš ï¸  Keep this cell running!\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "!python src/webui.py --share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
